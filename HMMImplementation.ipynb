{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import os\n",
    "from matplotlib import pyplot as plt \n",
    "import mediapipe as mp \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from hmmlearn import hmm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"../DataSet\" \n",
    "actions = np.array(os.listdir(dir_path))\n",
    "\n",
    "\n",
    "results_path = os.path.join('data_results')\n",
    "\n",
    "\n",
    "\n",
    "for action in actions: \n",
    "    num_of_videos = os.listdir(dir_path+'/'+action)\n",
    "    for video in range(len(num_of_videos)): \n",
    "        try: \n",
    "            os.makedirs(os.path.join(results_path, action, str(video)))\n",
    "        except: \n",
    "            pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_map = {label: num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_files = []\n",
    "sequences, labels = [], []\n",
    "\n",
    "for action in actions: \n",
    "    file_list = os.listdir(dir_path+\"/\"+action)\n",
    "\n",
    "    for video in range(len(file_list)): \n",
    "        window = []\n",
    "        filename = file_list[video]\n",
    "        cap = cv2.VideoCapture(dir_path+\"/\"+action+\"/\"+filename)\n",
    "        num_of_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        for frame_num in range(num_of_frames): \n",
    "            try: \n",
    "                res = np.load(os.path.join(results_path, action, str(video), \"{}.npy\".format(frame_num)))\n",
    "                print(res)\n",
    "                window.append(res)\n",
    "                print(\"window\")\n",
    "                print(window)\n",
    "            except FileNotFoundError: \n",
    "                missing_files.append(action + '/' + str(video)+ '/' +str(frame_num))\n",
    "                print(\"Missing \")\n",
    "                print(missing_files)\n",
    "                continue\n",
    "        sequences.append(window)\n",
    "        labels.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "Y= np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = np.array([label_map[label] for label in y_train])\n",
    "y_test_encoded = np.array([label_map[label] for label in y_test])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter tuning \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial): \n",
    "    n_components = trial.suggest_int('n_components',1,5, step=1)\n",
    "    covariance_type = trial.suggest_categorical('covariance_type', ['spherical', 'diag', 'tied','full'])\n",
    "    models = [hmm.GaussianHMM(n_components=n_components, covariance_type= covariance_type, n_iter=1000) for _ in range(n_classes)]\n",
    "\n",
    "    for gesture_class in range(n_classes): \n",
    "        gesture_sequences = X_train[y_train_encoded  == gesture_class]\n",
    "        lengths = [len(seq) for seq in gesture_sequences]\n",
    "        concatenated_sequences = np.concatenate(gesture_sequences)\n",
    "        models[gesture_class].fit(concatenated_sequences, lengths)\n",
    "    \n",
    "    y_pred = []\n",
    "    for sequence in X_test: \n",
    "        likelihoods = [model.score(sequence) for model in models]\n",
    "        y_pred.append(np.argmax(likelihoods))\n",
    "\n",
    "    accuracy = accuracy_score (y_test_encoded, y_pred)\n",
    "    print(accuracy)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=40)\n",
    "best_trial = study.best_trial \n",
    "print(f\"Best trial:{best_trial.number}, val_accurracy: {best_trial.value}, params: {best_trial.params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "n_components = best_params[\"n_components\"]\n",
    "covariance_type = best_params[\"covariance_type\"]\n",
    "print(covariance_type)\n",
    "print(n_components)\n",
    "models =[hmm.GaussianHMM(n_components=3, covariance_type='tied', n_iter=1000) for _ in range(n_classes)] \n",
    "\n",
    "for gesture_class in range(n_classes): \n",
    "    gesture_sequences = X_train[y_train_encoded  == gesture_class]\n",
    "    lengths = [len(seq) for seq in gesture_sequences]\n",
    "    concatenated_sequences = np.concatenate(gesture_sequences)\n",
    "    models[gesture_class].fit(concatenated_sequences, lengths)\n",
    "    \n",
    "y_pred = []\n",
    "for sequence in X_test: \n",
    "    likelihoods = [model.score(sequence) for model in models]\n",
    "    y_pred.append(np.argmax(likelihoods))\n",
    "\n",
    "accuracy = accuracy_score (y_test_encoded, y_pred)\n",
    "print(f\"Classification accuracy with the best hyperparameters: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(f\"Classification accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(y_test_encoded,y_pred))\n",
    "cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = ['Blue', 'Family', 'Happy', 'Man']\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.ylabel('True label')\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"hmm_models_66_percent\", \"wb\") as f: \n",
    "    pickle.dump(models,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./hmm_models_66_percent','rb') as file: \n",
    "    model = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
